input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/postgres_driver/postgresql-42.6.0.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://78.110.122.137:5432/blackeveryday"
    jdbc_user => "blackeveryday"
    jdbc_password => "e34fc3w#@32fwergt"
    jdbc_paging_enabled => true
    jdbc_page_size => 300000
    # jdbc_fetch_size = 500000
    # statement => "SELECT id, uuid, title_fa, title_en, category1, brand, website, website_url, url, is_active, image, selling_price, rrp_price, discount_price, discount_percent, write_date FROM blackeveryday_vw_productprice WHERE write_date > :sql_last_value AND image <> ''"
    statement => "SELECT id, uuid, title_fa, title_en, category1, brand, website, website_url, url, is_active, image, selling_price, rrp_price, discount_price, discount_percent, write_date, website_id, is_fake, home_show FROM blackeveryday_vw_productprice"

    # schedule => "*/20 * * * *"
    # connection_retry_attempts => 3
    use_column_value => true
    tracking_column => "write_date"
    tracking_column_type => "timestamp"
    # last_run_metadata_path => "/usr/share/logstash/.logstash_jdbc_last_run"
    # clean_run => true
    # record_last_run => true
  }
}

# filter {
#   mutate {
#     add_field => {
#       "suggested_title" => "%{title_fa}"
#       "typed_title" => "%{title_fa}"

#     }
#   }
#   # ruby {
#   #   code =>  "
#   #       words = event.get('title_fa').split
#   #       event.set('first_title', words[0,3].join(' ')) if words.size > 2
#   #     "
#   # }
# }



# filter {
#   mutate {
#     add_field => {
#       "concat_id_url" => "%{uuid}%{website_url}" # This will concatenate id and website_url
#     }
#   }
# }

output {
  elasticsearch {
    hosts => ["https://es01:9200"]
    user => "elastic"
    password => "M@cadamia2023"
    cacert => "certs/ca/ca.crt" 
    index => "blackeveryday_product"
  }
}